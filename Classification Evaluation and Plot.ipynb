{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = './Data/'\n",
    "\n",
    "filename = os.path.join(path, \"iris.csv\")\n",
    "df = pd.read_csv(filename, na_values=['NA','?'])\n",
    "df[0:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n"
     ]
    }
   ],
   "source": [
    "def encode_text_index(df, name):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    df[name] = le.fit_transform(df[name])\n",
    "    return le.classes_\n",
    "\n",
    "def to_xy(df, target):\n",
    "    result = []\n",
    "    for x in df.columns:\n",
    "        if x != target:\n",
    "            result.append(x)\n",
    "    # find out the type of the target column.  Is it really this hard? :(\n",
    "    target_type = df[target].dtypes\n",
    "    target_type = target_type[0] if hasattr(target_type, '__iter__') else target_type\n",
    "    # Encode to int for classification, float otherwise. TensorFlow likes 32 bits.\n",
    "    if target_type in (np.int64, np.int32):\n",
    "        # Classification\n",
    "        dummies = pd.get_dummies(df[target])\n",
    "        return df.as_matrix(result).astype(np.float32), dummies.as_matrix().astype(np.float32)\n",
    "    else:\n",
    "        # Regression\n",
    "        return df.as_matrix(result).astype(np.float32), df.as_matrix([target]).astype(np.float32)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "species = encode_text_index(df, \"species\")\n",
    "\n",
    "x,y = to_xy(df, \"species\")\n",
    "\n",
    "# Split into train and test\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "x,y,test_size = 0.25, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples, validate on 38 samples\n",
      "Epoch 1/1000\n",
      " - 1s - loss: 1.7774 - val_loss: 1.5971\n",
      "Epoch 2/1000\n",
      " - 0s - loss: 1.6165 - val_loss: 1.4820\n",
      "Epoch 3/1000\n",
      " - 0s - loss: 1.4730 - val_loss: 1.3963\n",
      "Epoch 4/1000\n",
      " - 0s - loss: 1.3805 - val_loss: 1.3374\n",
      "Epoch 5/1000\n",
      " - 0s - loss: 1.3085 - val_loss: 1.2986\n",
      "Epoch 6/1000\n",
      " - 0s - loss: 1.2638 - val_loss: 1.2701\n",
      "Epoch 7/1000\n",
      " - 0s - loss: 1.2262 - val_loss: 1.2442\n",
      "Epoch 8/1000\n",
      " - 0s - loss: 1.1962 - val_loss: 1.2165\n",
      "Epoch 9/1000\n",
      " - 0s - loss: 1.1699 - val_loss: 1.1878\n",
      "Epoch 10/1000\n",
      " - 0s - loss: 1.1433 - val_loss: 1.1611\n",
      "Epoch 11/1000\n",
      " - 0s - loss: 1.1193 - val_loss: 1.1320\n",
      "Epoch 12/1000\n",
      " - 0s - loss: 1.0951 - val_loss: 1.1043\n",
      "Epoch 13/1000\n",
      " - 0s - loss: 1.0710 - val_loss: 1.0784\n",
      "Epoch 14/1000\n",
      " - 0s - loss: 1.0484 - val_loss: 1.0543\n",
      "Epoch 15/1000\n",
      " - 0s - loss: 1.0272 - val_loss: 1.0303\n",
      "Epoch 16/1000\n",
      " - 0s - loss: 1.0059 - val_loss: 1.0073\n",
      "Epoch 17/1000\n",
      " - 0s - loss: 0.9858 - val_loss: 0.9869\n",
      "Epoch 18/1000\n",
      " - 0s - loss: 0.9666 - val_loss: 0.9645\n",
      "Epoch 19/1000\n",
      " - 0s - loss: 0.9463 - val_loss: 0.9434\n",
      "Epoch 20/1000\n",
      " - 0s - loss: 0.9277 - val_loss: 0.9227\n",
      "Epoch 21/1000\n",
      " - 0s - loss: 0.9093 - val_loss: 0.9035\n",
      "Epoch 22/1000\n",
      " - 0s - loss: 0.8916 - val_loss: 0.8846\n",
      "Epoch 23/1000\n",
      " - 0s - loss: 0.8744 - val_loss: 0.8659\n",
      "Epoch 24/1000\n",
      " - 0s - loss: 0.8572 - val_loss: 0.8484\n",
      "Epoch 25/1000\n",
      " - 0s - loss: 0.8407 - val_loss: 0.8309\n",
      "Epoch 26/1000\n",
      " - 0s - loss: 0.8245 - val_loss: 0.8140\n",
      "Epoch 27/1000\n",
      " - 0s - loss: 0.8097 - val_loss: 0.7965\n",
      "Epoch 28/1000\n",
      " - 0s - loss: 0.7938 - val_loss: 0.7808\n",
      "Epoch 29/1000\n",
      " - 0s - loss: 0.7789 - val_loss: 0.7650\n",
      "Epoch 30/1000\n",
      " - 0s - loss: 0.7645 - val_loss: 0.7497\n",
      "Epoch 31/1000\n",
      " - 0s - loss: 0.7512 - val_loss: 0.7344\n",
      "Epoch 32/1000\n",
      " - 0s - loss: 0.7371 - val_loss: 0.7201\n",
      "Epoch 33/1000\n",
      " - 0s - loss: 0.7240 - val_loss: 0.7072\n",
      "Epoch 34/1000\n",
      " - 0s - loss: 0.7113 - val_loss: 0.6940\n",
      "Epoch 35/1000\n",
      " - 0s - loss: 0.6989 - val_loss: 0.6810\n",
      "Epoch 36/1000\n",
      " - 0s - loss: 0.6868 - val_loss: 0.6683\n",
      "Epoch 37/1000\n",
      " - 0s - loss: 0.6754 - val_loss: 0.6558\n",
      "Epoch 38/1000\n",
      " - 0s - loss: 0.6641 - val_loss: 0.6438\n",
      "Epoch 39/1000\n",
      " - 0s - loss: 0.6537 - val_loss: 0.6326\n",
      "Epoch 40/1000\n",
      " - 0s - loss: 0.6429 - val_loss: 0.6212\n",
      "Epoch 41/1000\n",
      " - 0s - loss: 0.6330 - val_loss: 0.6104\n",
      "Epoch 42/1000\n",
      " - 0s - loss: 0.6230 - val_loss: 0.6008\n",
      "Epoch 43/1000\n",
      " - 0s - loss: 0.6137 - val_loss: 0.5911\n",
      "Epoch 44/1000\n",
      " - 0s - loss: 0.6046 - val_loss: 0.5825\n",
      "Epoch 45/1000\n",
      " - 0s - loss: 0.5959 - val_loss: 0.5736\n",
      "Epoch 46/1000\n",
      " - 0s - loss: 0.5876 - val_loss: 0.5644\n",
      "Epoch 47/1000\n",
      " - 0s - loss: 0.5793 - val_loss: 0.5558\n",
      "Epoch 48/1000\n",
      " - 0s - loss: 0.5715 - val_loss: 0.5478\n",
      "Epoch 49/1000\n",
      " - 0s - loss: 0.5642 - val_loss: 0.5401\n",
      "Epoch 50/1000\n",
      " - 0s - loss: 0.5567 - val_loss: 0.5325\n",
      "Epoch 51/1000\n",
      " - 0s - loss: 0.5499 - val_loss: 0.5249\n",
      "Epoch 52/1000\n",
      " - 0s - loss: 0.5431 - val_loss: 0.5179\n",
      "Epoch 53/1000\n",
      " - 0s - loss: 0.5366 - val_loss: 0.5113\n",
      "Epoch 54/1000\n",
      " - 0s - loss: 0.5305 - val_loss: 0.5048\n",
      "Epoch 55/1000\n",
      " - 0s - loss: 0.5243 - val_loss: 0.4989\n",
      "Epoch 56/1000\n",
      " - 0s - loss: 0.5186 - val_loss: 0.4929\n",
      "Epoch 57/1000\n",
      " - 0s - loss: 0.5128 - val_loss: 0.4876\n",
      "Epoch 58/1000\n",
      " - 0s - loss: 0.5071 - val_loss: 0.4823\n",
      "Epoch 59/1000\n",
      " - 0s - loss: 0.5020 - val_loss: 0.4771\n",
      "Epoch 60/1000\n",
      " - 0s - loss: 0.4973 - val_loss: 0.4714\n",
      "Epoch 61/1000\n",
      " - 0s - loss: 0.4919 - val_loss: 0.4666\n",
      "Epoch 62/1000\n",
      " - 0s - loss: 0.4871 - val_loss: 0.4615\n",
      "Epoch 63/1000\n",
      " - 0s - loss: 0.4823 - val_loss: 0.4569\n",
      "Epoch 64/1000\n",
      " - 0s - loss: 0.4778 - val_loss: 0.4521\n",
      "Epoch 65/1000\n",
      " - 0s - loss: 0.4734 - val_loss: 0.4475\n",
      "Epoch 66/1000\n",
      " - 0s - loss: 0.4691 - val_loss: 0.4433\n",
      "Epoch 67/1000\n",
      " - 0s - loss: 0.4649 - val_loss: 0.4393\n",
      "Epoch 68/1000\n",
      " - 0s - loss: 0.4607 - val_loss: 0.4352\n",
      "Epoch 69/1000\n",
      " - 0s - loss: 0.4568 - val_loss: 0.4311\n",
      "Epoch 70/1000\n",
      " - 0s - loss: 0.4527 - val_loss: 0.4271\n",
      "Epoch 71/1000\n",
      " - 0s - loss: 0.4487 - val_loss: 0.4229\n",
      "Epoch 72/1000\n",
      " - 0s - loss: 0.4452 - val_loss: 0.4189\n",
      "Epoch 73/1000\n",
      " - 0s - loss: 0.4415 - val_loss: 0.4152\n",
      "Epoch 74/1000\n",
      " - 0s - loss: 0.4377 - val_loss: 0.4117\n",
      "Epoch 75/1000\n",
      " - 0s - loss: 0.4343 - val_loss: 0.4086\n",
      "Epoch 76/1000\n",
      " - 0s - loss: 0.4305 - val_loss: 0.4051\n",
      "Epoch 77/1000\n",
      " - 0s - loss: 0.4271 - val_loss: 0.4015\n",
      "Epoch 78/1000\n",
      " - 0s - loss: 0.4236 - val_loss: 0.3983\n",
      "Epoch 79/1000\n",
      " - 0s - loss: 0.4201 - val_loss: 0.3948\n",
      "Epoch 80/1000\n",
      " - 0s - loss: 0.4184 - val_loss: 0.3921\n",
      "Epoch 81/1000\n",
      " - 0s - loss: 0.4134 - val_loss: 0.3881\n",
      "Epoch 82/1000\n",
      " - 0s - loss: 0.4100 - val_loss: 0.3846\n",
      "Epoch 83/1000\n",
      " - 0s - loss: 0.4068 - val_loss: 0.3813\n",
      "Epoch 84/1000\n",
      " - 0s - loss: 0.4035 - val_loss: 0.3783\n",
      "Epoch 85/1000\n",
      " - 0s - loss: 0.4002 - val_loss: 0.3751\n",
      "Epoch 86/1000\n",
      " - 0s - loss: 0.3973 - val_loss: 0.3725\n",
      "Epoch 87/1000\n",
      " - 0s - loss: 0.3938 - val_loss: 0.3694\n",
      "Epoch 88/1000\n",
      " - 0s - loss: 0.3908 - val_loss: 0.3661\n",
      "Epoch 89/1000\n",
      " - 0s - loss: 0.3875 - val_loss: 0.3630\n",
      "Epoch 90/1000\n",
      " - 0s - loss: 0.3845 - val_loss: 0.3606\n",
      "Epoch 91/1000\n",
      " - 0s - loss: 0.3813 - val_loss: 0.3577\n",
      "Epoch 92/1000\n",
      " - 0s - loss: 0.3781 - val_loss: 0.3545\n",
      "Epoch 93/1000\n",
      " - 0s - loss: 0.3750 - val_loss: 0.3510\n",
      "Epoch 94/1000\n",
      " - 0s - loss: 0.3718 - val_loss: 0.3481\n",
      "Epoch 95/1000\n",
      " - 0s - loss: 0.3687 - val_loss: 0.3453\n",
      "Epoch 96/1000\n",
      " - 0s - loss: 0.3657 - val_loss: 0.3425\n",
      "Epoch 97/1000\n",
      " - 0s - loss: 0.3626 - val_loss: 0.3402\n",
      "Epoch 98/1000\n",
      " - 0s - loss: 0.3598 - val_loss: 0.3374\n",
      "Epoch 99/1000\n",
      " - 0s - loss: 0.3570 - val_loss: 0.3342\n",
      "Epoch 100/1000\n",
      " - 0s - loss: 0.3538 - val_loss: 0.3308\n",
      "Epoch 101/1000\n",
      " - 0s - loss: 0.3506 - val_loss: 0.3281\n",
      "Epoch 102/1000\n",
      " - 0s - loss: 0.3481 - val_loss: 0.3250\n",
      "Epoch 103/1000\n",
      " - 0s - loss: 0.3447 - val_loss: 0.3224\n",
      "Epoch 104/1000\n",
      " - 0s - loss: 0.3415 - val_loss: 0.3195\n",
      "Epoch 105/1000\n",
      " - 0s - loss: 0.3386 - val_loss: 0.3166\n",
      "Epoch 106/1000\n",
      " - 0s - loss: 0.3358 - val_loss: 0.3140\n",
      "Epoch 107/1000\n",
      " - 0s - loss: 0.3327 - val_loss: 0.3110\n",
      "Epoch 108/1000\n",
      " - 0s - loss: 0.3296 - val_loss: 0.3083\n",
      "Epoch 109/1000\n",
      " - 0s - loss: 0.3269 - val_loss: 0.3058\n",
      "Epoch 110/1000\n",
      " - 0s - loss: 0.3239 - val_loss: 0.3029\n",
      "Epoch 111/1000\n",
      " - 0s - loss: 0.3209 - val_loss: 0.3002\n",
      "Epoch 112/1000\n",
      " - 0s - loss: 0.3184 - val_loss: 0.2981\n",
      "Epoch 113/1000\n",
      " - 0s - loss: 0.3154 - val_loss: 0.2953\n",
      "Epoch 114/1000\n",
      " - 0s - loss: 0.3124 - val_loss: 0.2928\n",
      "Epoch 115/1000\n",
      " - 0s - loss: 0.3095 - val_loss: 0.2898\n",
      "Epoch 116/1000\n",
      " - 0s - loss: 0.3066 - val_loss: 0.2871\n",
      "Epoch 117/1000\n",
      " - 0s - loss: 0.3036 - val_loss: 0.2844\n",
      "Epoch 118/1000\n",
      " - 0s - loss: 0.3012 - val_loss: 0.2816\n",
      "Epoch 119/1000\n",
      " - 0s - loss: 0.2984 - val_loss: 0.2788\n",
      "Epoch 120/1000\n",
      " - 0s - loss: 0.2954 - val_loss: 0.2763\n",
      "Epoch 121/1000\n",
      " - 0s - loss: 0.2924 - val_loss: 0.2740\n",
      "Epoch 122/1000\n",
      " - 0s - loss: 0.2910 - val_loss: 0.2727\n",
      "Epoch 123/1000\n",
      " - 0s - loss: 0.2875 - val_loss: 0.2695\n",
      "Epoch 124/1000\n",
      " - 0s - loss: 0.2844 - val_loss: 0.2667\n",
      "Epoch 125/1000\n",
      " - 0s - loss: 0.2816 - val_loss: 0.2640\n",
      "Epoch 126/1000\n",
      " - 0s - loss: 0.2789 - val_loss: 0.2609\n",
      "Epoch 127/1000\n",
      " - 0s - loss: 0.2763 - val_loss: 0.2584\n",
      "Epoch 128/1000\n",
      " - 0s - loss: 0.2737 - val_loss: 0.2561\n",
      "Epoch 129/1000\n",
      " - 0s - loss: 0.2709 - val_loss: 0.2538\n",
      "Epoch 130/1000\n",
      " - 0s - loss: 0.2688 - val_loss: 0.2512\n",
      "Epoch 131/1000\n",
      " - 0s - loss: 0.2661 - val_loss: 0.2495\n",
      "Epoch 132/1000\n",
      " - 0s - loss: 0.2639 - val_loss: 0.2478\n",
      "Epoch 133/1000\n",
      " - 0s - loss: 0.2605 - val_loss: 0.2447\n",
      "Epoch 134/1000\n",
      " - 0s - loss: 0.2580 - val_loss: 0.2416\n",
      "Epoch 135/1000\n",
      " - 0s - loss: 0.2562 - val_loss: 0.2390\n",
      "Epoch 136/1000\n",
      " - 0s - loss: 0.2533 - val_loss: 0.2369\n",
      "Epoch 137/1000\n",
      " - 0s - loss: 0.2511 - val_loss: 0.2353\n",
      "Epoch 138/1000\n",
      " - 0s - loss: 0.2480 - val_loss: 0.2327\n",
      "Epoch 139/1000\n",
      " - 0s - loss: 0.2455 - val_loss: 0.2303\n",
      "Epoch 140/1000\n",
      " - 0s - loss: 0.2430 - val_loss: 0.2281\n",
      "Epoch 141/1000\n",
      " - 0s - loss: 0.2422 - val_loss: 0.2270\n",
      "Epoch 142/1000\n",
      " - 0s - loss: 0.2387 - val_loss: 0.2237\n",
      "Epoch 143/1000\n",
      " - 0s - loss: 0.2359 - val_loss: 0.2215\n",
      "Epoch 144/1000\n",
      " - 0s - loss: 0.2345 - val_loss: 0.2190\n",
      "Epoch 145/1000\n",
      " - 0s - loss: 0.2310 - val_loss: 0.2174\n",
      "Epoch 146/1000\n",
      " - 0s - loss: 0.2311 - val_loss: 0.2176\n",
      "Epoch 147/1000\n",
      " - 0s - loss: 0.2275 - val_loss: 0.2136\n",
      "Epoch 148/1000\n",
      " - 0s - loss: 0.2253 - val_loss: 0.2107\n",
      "Epoch 149/1000\n",
      " - 0s - loss: 0.2225 - val_loss: 0.2089\n",
      "Epoch 150/1000\n",
      " - 0s - loss: 0.2210 - val_loss: 0.2077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 151/1000\n",
      " - 0s - loss: 0.2184 - val_loss: 0.2053\n",
      "Epoch 152/1000\n",
      " - 0s - loss: 0.2173 - val_loss: 0.2028\n",
      "Epoch 153/1000\n",
      " - 0s - loss: 0.2148 - val_loss: 0.2015\n",
      "Epoch 154/1000\n",
      " - 0s - loss: 0.2127 - val_loss: 0.2003\n",
      "Epoch 155/1000\n",
      " - 0s - loss: 0.2101 - val_loss: 0.1977\n",
      "Epoch 156/1000\n",
      " - 0s - loss: 0.2082 - val_loss: 0.1958\n",
      "Epoch 157/1000\n",
      " - 0s - loss: 0.2063 - val_loss: 0.1936\n",
      "Epoch 158/1000\n",
      " - 0s - loss: 0.2043 - val_loss: 0.1919\n",
      "Epoch 159/1000\n",
      " - 0s - loss: 0.2025 - val_loss: 0.1906\n",
      "Epoch 160/1000\n",
      " - 0s - loss: 0.2003 - val_loss: 0.1887\n",
      "Epoch 161/1000\n",
      " - 0s - loss: 0.1988 - val_loss: 0.1868\n",
      "Epoch 162/1000\n",
      " - 0s - loss: 0.1969 - val_loss: 0.1856\n",
      "Epoch 163/1000\n",
      " - 0s - loss: 0.1949 - val_loss: 0.1835\n",
      "Epoch 164/1000\n",
      " - 0s - loss: 0.1932 - val_loss: 0.1816\n",
      "Epoch 165/1000\n",
      " - 0s - loss: 0.1914 - val_loss: 0.1802\n",
      "Epoch 166/1000\n",
      " - 0s - loss: 0.1904 - val_loss: 0.1794\n",
      "Epoch 167/1000\n",
      " - 0s - loss: 0.1882 - val_loss: 0.1771\n",
      "Epoch 168/1000\n",
      " - 0s - loss: 0.1864 - val_loss: 0.1758\n",
      "Epoch 169/1000\n",
      " - 0s - loss: 0.1847 - val_loss: 0.1738\n",
      "Epoch 170/1000\n",
      " - 0s - loss: 0.1831 - val_loss: 0.1720\n",
      "Epoch 171/1000\n",
      " - 0s - loss: 0.1820 - val_loss: 0.1713\n",
      "Epoch 172/1000\n",
      " - 0s - loss: 0.1797 - val_loss: 0.1694\n",
      "Epoch 173/1000\n",
      " - 0s - loss: 0.1780 - val_loss: 0.1679\n",
      "Epoch 174/1000\n",
      " - 0s - loss: 0.1766 - val_loss: 0.1664\n",
      "Epoch 175/1000\n",
      " - 0s - loss: 0.1749 - val_loss: 0.1655\n",
      "Epoch 176/1000\n",
      " - 0s - loss: 0.1736 - val_loss: 0.1645\n",
      "Epoch 177/1000\n",
      " - 0s - loss: 0.1721 - val_loss: 0.1628\n",
      "Epoch 178/1000\n",
      " - 0s - loss: 0.1715 - val_loss: 0.1600\n",
      "Epoch 179/1000\n",
      " - 0s - loss: 0.1691 - val_loss: 0.1589\n",
      "Epoch 180/1000\n",
      " - 0s - loss: 0.1676 - val_loss: 0.1586\n",
      "Epoch 181/1000\n",
      " - 0s - loss: 0.1667 - val_loss: 0.1581\n",
      "Epoch 182/1000\n",
      " - 0s - loss: 0.1647 - val_loss: 0.1557\n",
      "Epoch 183/1000\n",
      " - 0s - loss: 0.1631 - val_loss: 0.1534\n",
      "Epoch 184/1000\n",
      " - 0s - loss: 0.1626 - val_loss: 0.1519\n",
      "Epoch 185/1000\n",
      " - 0s - loss: 0.1612 - val_loss: 0.1515\n",
      "Epoch 186/1000\n",
      " - 0s - loss: 0.1592 - val_loss: 0.1507\n",
      "Epoch 187/1000\n",
      " - 0s - loss: 0.1586 - val_loss: 0.1505\n",
      "Epoch 188/1000\n",
      " - 0s - loss: 0.1574 - val_loss: 0.1478\n",
      "Epoch 189/1000\n",
      " - 0s - loss: 0.1560 - val_loss: 0.1469\n",
      "Epoch 190/1000\n",
      " - 0s - loss: 0.1542 - val_loss: 0.1456\n",
      "Epoch 191/1000\n",
      " - 0s - loss: 0.1531 - val_loss: 0.1443\n",
      "Epoch 192/1000\n",
      " - 0s - loss: 0.1519 - val_loss: 0.1427\n",
      "Epoch 193/1000\n",
      " - 0s - loss: 0.1515 - val_loss: 0.1414\n",
      "Epoch 194/1000\n",
      " - 0s - loss: 0.1494 - val_loss: 0.1419\n",
      "Epoch 195/1000\n",
      " - 0s - loss: 0.1490 - val_loss: 0.1420\n",
      "Epoch 196/1000\n",
      " - 0s - loss: 0.1475 - val_loss: 0.1397\n",
      "Epoch 197/1000\n",
      " - 0s - loss: 0.1479 - val_loss: 0.1369\n",
      "Epoch 198/1000\n",
      " - 0s - loss: 0.1454 - val_loss: 0.1366\n",
      "Epoch 199/1000\n",
      " - 0s - loss: 0.1441 - val_loss: 0.1357\n",
      "Epoch 200/1000\n",
      " - 0s - loss: 0.1435 - val_loss: 0.1360\n",
      "Epoch 201/1000\n",
      " - 0s - loss: 0.1422 - val_loss: 0.1343\n",
      "Epoch 202/1000\n",
      " - 0s - loss: 0.1408 - val_loss: 0.1328\n",
      "Epoch 203/1000\n",
      " - 0s - loss: 0.1403 - val_loss: 0.1314\n",
      "Epoch 204/1000\n",
      " - 0s - loss: 0.1390 - val_loss: 0.1301\n",
      "Epoch 205/1000\n",
      " - 0s - loss: 0.1380 - val_loss: 0.1295\n",
      "Epoch 206/1000\n",
      " - 0s - loss: 0.1371 - val_loss: 0.1306\n",
      "Epoch 207/1000\n",
      " - 0s - loss: 0.1370 - val_loss: 0.1304\n",
      "Epoch 208/1000\n",
      " - 0s - loss: 0.1351 - val_loss: 0.1279\n",
      "Epoch 209/1000\n",
      " - 0s - loss: 0.1357 - val_loss: 0.1251\n",
      "Epoch 210/1000\n",
      " - 0s - loss: 0.1337 - val_loss: 0.1250\n",
      "Epoch 211/1000\n",
      " - 0s - loss: 0.1327 - val_loss: 0.1252\n",
      "Epoch 212/1000\n",
      " - 0s - loss: 0.1316 - val_loss: 0.1233\n",
      "Epoch 213/1000\n",
      " - 0s - loss: 0.1305 - val_loss: 0.1226\n",
      "Epoch 214/1000\n",
      " - 0s - loss: 0.1304 - val_loss: 0.1233\n",
      "Epoch 215/1000\n",
      " - 0s - loss: 0.1288 - val_loss: 0.1218\n",
      "Epoch 216/1000\n",
      " - 0s - loss: 0.1279 - val_loss: 0.1206\n",
      "Epoch 217/1000\n",
      " - 0s - loss: 0.1271 - val_loss: 0.1188\n",
      "Epoch 218/1000\n",
      " - 0s - loss: 0.1266 - val_loss: 0.1182\n",
      "Epoch 219/1000\n",
      " - 0s - loss: 0.1263 - val_loss: 0.1169\n",
      "Epoch 220/1000\n",
      " - 0s - loss: 0.1247 - val_loss: 0.1173\n",
      "Epoch 221/1000\n",
      " - 0s - loss: 0.1237 - val_loss: 0.1181\n",
      "Epoch 222/1000\n",
      " - 0s - loss: 0.1235 - val_loss: 0.1177\n",
      "Epoch 223/1000\n",
      " - 0s - loss: 0.1226 - val_loss: 0.1158\n",
      "Epoch 224/1000\n",
      " - 0s - loss: 0.1215 - val_loss: 0.1138\n",
      "Epoch 225/1000\n",
      " - 0s - loss: 0.1209 - val_loss: 0.1129\n",
      "Epoch 226/1000\n",
      " - 0s - loss: 0.1204 - val_loss: 0.1123\n",
      "Epoch 227/1000\n",
      " - 0s - loss: 0.1198 - val_loss: 0.1115\n",
      "Epoch 228/1000\n",
      " - 0s - loss: 0.1191 - val_loss: 0.1107\n",
      "Epoch 229/1000\n",
      " - 0s - loss: 0.1182 - val_loss: 0.1105\n",
      "Epoch 230/1000\n",
      " - 0s - loss: 0.1174 - val_loss: 0.1109\n",
      "Epoch 231/1000\n",
      " - 0s - loss: 0.1172 - val_loss: 0.1099\n",
      "Epoch 232/1000\n",
      " - 0s - loss: 0.1162 - val_loss: 0.1110\n",
      "Epoch 233/1000\n",
      " - 0s - loss: 0.1165 - val_loss: 0.1092\n",
      "Epoch 234/1000\n",
      " - 0s - loss: 0.1148 - val_loss: 0.1091\n",
      "Epoch 235/1000\n",
      " - 0s - loss: 0.1144 - val_loss: 0.1086\n",
      "Epoch 236/1000\n",
      " - 0s - loss: 0.1143 - val_loss: 0.1062\n",
      "Epoch 237/1000\n",
      " - 0s - loss: 0.1131 - val_loss: 0.1066\n",
      "Epoch 238/1000\n",
      " - 0s - loss: 0.1133 - val_loss: 0.1050\n",
      "Epoch 239/1000\n",
      " - 0s - loss: 0.1116 - val_loss: 0.1051\n",
      "Epoch 240/1000\n",
      " - 0s - loss: 0.1115 - val_loss: 0.1061\n",
      "Epoch 241/1000\n",
      " - 0s - loss: 0.1121 - val_loss: 0.1066\n",
      "Epoch 242/1000\n",
      " - 0s - loss: 0.1127 - val_loss: 0.1019\n",
      "Epoch 243/1000\n",
      " - 0s - loss: 0.1096 - val_loss: 0.1022\n",
      "Epoch 244/1000\n",
      " - 0s - loss: 0.1090 - val_loss: 0.1023\n",
      "Epoch 245/1000\n",
      " - 0s - loss: 0.1083 - val_loss: 0.1009\n",
      "Epoch 246/1000\n",
      " - 0s - loss: 0.1076 - val_loss: 0.1007\n",
      "Epoch 247/1000\n",
      " - 0s - loss: 0.1076 - val_loss: 0.1007\n",
      "Epoch 248/1000\n",
      " - 0s - loss: 0.1079 - val_loss: 0.0986\n",
      "Epoch 249/1000\n",
      " - 0s - loss: 0.1062 - val_loss: 0.0989\n",
      "Epoch 250/1000\n",
      " - 0s - loss: 0.1053 - val_loss: 0.1005\n",
      "Epoch 251/1000\n",
      " - 0s - loss: 0.1061 - val_loss: 0.1012\n",
      "Epoch 252/1000\n",
      " - 0s - loss: 0.1044 - val_loss: 0.0980\n",
      "Epoch 253/1000\n",
      " - 0s - loss: 0.1039 - val_loss: 0.0955\n",
      "Epoch 254/1000\n",
      " - 0s - loss: 0.1045 - val_loss: 0.0953\n",
      "Epoch 255/1000\n",
      " - 0s - loss: 0.1035 - val_loss: 0.0962\n",
      "Epoch 256/1000\n",
      " - 0s - loss: 0.1040 - val_loss: 0.0951\n",
      "Epoch 257/1000\n",
      " - 0s - loss: 0.1022 - val_loss: 0.0977\n",
      "Epoch 258/1000\n",
      " - 0s - loss: 0.1026 - val_loss: 0.0972\n",
      "Epoch 00258: early stopping\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Unable to open file (unable to open file: name = 'best_weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-3e3e9810b6a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m          \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m          epochs=1000)\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'best_weights.hdf5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36mload_weights\u001b[1;34m(self, filepath, by_name, skip_mismatch, reshape)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mh5py\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'`load_weights` requires h5py.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;34m'layer_names'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'model_weights'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m                 \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'model_weights'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, **kwds)\u001b[0m\n\u001b[0;32m    267\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mphil\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m                 \u001b[0mfapl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fapl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 269\u001b[1;33m                 \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_fid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muserblock_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mswmr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mswmr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    270\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    271\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m     97\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m             \u001b[0mflags\u001b[0m \u001b[1;33m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'r+'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'best_weights.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "model = Sequential()\n",
    "model.add(Dense(10,\n",
    "                input_dim=x.shape[1],\n",
    "               activation='relu'))\n",
    "model.add(Dense(5,\n",
    "               activation='relu'))\n",
    "model.add(Dense(y.shape[1],\n",
    "               activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "             optimizer='adam')\n",
    "monitor=EarlyStopping(monitor='val_loss',\n",
    "                     min_delta=1e-3,\n",
    "                     patience=5,\n",
    "                     verbose=1,\n",
    "                     mode='auto')\n",
    "checkpointer = ModelCheckpoint(filepath=\"best_weight.hdf5\",\n",
    "                              verbose=0,\n",
    "                              save_best_only=True)\n",
    "model.fit(x,y,validation_data=(x_test,y_test),\n",
    "         callbacks=[monitor, checkpointer],\n",
    "         verbose=2,\n",
    "         epochs=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9237204e-01 7.6279533e-03 3.5024919e-10]\n",
      " [8.4642716e-06 7.6937288e-02 9.2305422e-01]\n",
      " [9.8662704e-01 1.3372928e-02 3.9050421e-09]\n",
      " [6.1663557e-03 9.4982022e-01 4.4013467e-02]\n",
      " [2.9152298e-07 1.8266078e-02 9.8173368e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "import tensorflow as tf\n",
    "\n",
    "model.load_weights('best_weight.hdf5')\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "print(pred[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 2 2 2 0 2 0 1 0 0 0 1 2 2 1 0 2 0 1 2 1 0 2 1 1 0 0 0 1 2 0 2 0 1\n",
      " 1]\n"
     ]
    }
   ],
   "source": [
    "# raw probabilities to chosen class\n",
    "\n",
    "pred = np.argmax(pred, axis=1)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "y_compare = np.argmax(y_test, axis=1)\n",
    "score = metrics.accuracy_score(y_compare, pred)\n",
    "\n",
    "print(\"Accuracy score:{}\".format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy array of predcitions\n",
      "[99.2372  0.7628  0.    ]\n",
      "as percent probability\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9924, 0.0076, 0.    ],\n",
       "       [0.    , 0.0769, 0.9231],\n",
       "       [0.9866, 0.0134, 0.    ],\n",
       "       [0.0062, 0.9498, 0.044 ],\n",
       "       [0.    , 0.0183, 0.9817]], dtype=float32)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log loss score:0.09512243177864309\n"
     ]
    }
   ],
   "source": [
    "# calculate classification log loss\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "pred = model.predict(x_test)\n",
    "\n",
    "print(\"Numpy array of predcitions\")\n",
    "print(pred[0]*100)\n",
    "\n",
    "print(\"as percent probability\")\n",
    "display(pred[0:5])\n",
    "\n",
    "score = metrics.log_loss(y_test, pred)\n",
    "print(\"Log loss score:{}\".format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ashish\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: RuntimeWarning: divide by zero encountered in log\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, show\n",
    "from numpy import arange, sin, pi\n",
    "\n",
    "t = arange(0.0, 1.0, 0.00001)\n",
    "\n",
    "fig = figure(1,figsize=(12,10))\n",
    "\n",
    "ax1 = fig.add_subplot(211)\n",
    "ax1.plot(t, np.log(t))\n",
    "ax1.grid(True)\n",
    "ax1.set_ylim((-8,1.5))\n",
    "ax1.set_xlim((-0.1,2))\n",
    "\n",
    "show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
